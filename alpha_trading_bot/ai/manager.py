"""
AIç®¡ç†å™¨ - ç®¡ç†å¤šä¸ªAIæä¾›å•†çš„ä¿¡å·ç”Ÿæˆ
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from ..core.base import BaseComponent, BaseConfig
from ..core.exceptions import AIProviderError
from .client import AIClient
from .fusion import AIFusion
from .signals import SignalGenerator
from .model_selector import model_selector, ModelSelector
from .dynamic_cache import DynamicCacheManager, cache_manager
from .cache_monitor import cache_monitor
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class AIManagerConfig(BaseConfig):
    """AIç®¡ç†å™¨é…ç½®"""
    use_multi_ai: bool = False
    primary_provider: str = "kimi"
    fallback_enabled: bool = True
    cache_duration: int = 900
    min_confidence: float = 0.3
    fusion_enabled: bool = True
    enable_dynamic_model_selection: bool = True
    default_deepseek_model: str = "deepseek-chat"
    default_kimi_model: str = "moonshot-v1-32k"
    enable_dynamic_cache: bool = True  # å¯ç”¨åŠ¨æ€ç¼“å­˜

class AIManager(BaseComponent):
    """AIç®¡ç†å™¨"""

    def __init__(self, config: Optional[AIManagerConfig] = None):
        # å¦‚æœæ²¡æœ‰æä¾›é…ç½®ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
        if config is None:
            config = AIManagerConfig(name="AIManager")
        super().__init__(config)
        self.ai_client = AIClient()
        self.ai_fusion = AIFusion()
        self.signal_generator = SignalGenerator()
        self.cache: Dict[str, Any] = {}
        self.providers: List[str] = []
        self.dynamic_cache = cache_manager  # ä½¿ç”¨å…¨å±€åŠ¨æ€ç¼“å­˜ç®¡ç†å™¨
        self.dynamic_cache.config.base_duration = config.cache_duration  # åŒæ­¥é…ç½®

    async def initialize(self) -> bool:
        """åˆå§‹åŒ–AIç®¡ç†å™¨"""
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–AIç®¡ç†å™¨...")

            # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
            await self.ai_client.initialize()

            # è·å–é…ç½®
            from ..config import load_config
            config = load_config()

            # æ ¹æ®AIæ¨¡å¼é€‰æ‹©æä¾›å•†
            if config.ai.use_multi_ai_fusion:
                # å¤šAIèåˆæ¨¡å¼ - åªä½¿ç”¨é…ç½®çš„èåˆæä¾›å•†
                available_providers = set(config.ai.models.keys())
                fusion_providers = set(config.ai.ai_fusion_providers)

                # åªä¿ç•™åŒæ—¶æœ‰APIå¯†é’¥ä¸”åœ¨èåˆé…ç½®ä¸­çš„æä¾›å•†
                self.providers = list(available_providers & fusion_providers)

                if not self.providers:
                    logger.warning(f"é…ç½®çš„èåˆæä¾›å•† {fusion_providers} æ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥ï¼Œå°†ä½¿ç”¨å›é€€æ¨¡å¼")
                    self.providers = ["fallback"]
                else:
                    logger.info(f"AIèåˆæ¨¡å¼å·²å¯ç”¨ï¼Œä½¿ç”¨æä¾›å•†: {self.providers}")
            else:
                # å•ä¸€AIæ¨¡å¼ - åªä½¿ç”¨é»˜è®¤æä¾›å•†
                default_provider = config.ai.ai_default_provider
                if default_provider in config.ai.models:
                    self.providers = [default_provider]
                    logger.info(f"å•ä¸€AIæ¨¡å¼ï¼Œä½¿ç”¨æä¾›å•†: {default_provider}")
                else:
                    logger.warning(f"é»˜è®¤æä¾›å•† {default_provider} æœªé…ç½®APIå¯†é’¥ï¼Œå°†ä½¿ç”¨å›é€€æ¨¡å¼")
                    self.providers = ["fallback"]

            # åˆå§‹åŒ–ä¿¡å·ç”Ÿæˆå™¨
            await self.signal_generator.initialize()

            self._initialized = True
            logger.info(f"AIç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œå¯ç”¨æä¾›å•†: {self.providers}")
            return True

        except Exception as e:
            logger.error(f"AIç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        await self.ai_client.cleanup()

    async def generate_signals(self, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”ŸæˆAIäº¤æ˜“ä¿¡å·"""
        try:
            # æ£€æŸ¥ç¼“å­˜ - æ”¯æŒåŠ¨æ€ç¼“å­˜å’Œä¼ ç»Ÿç¼“å­˜
            if self.config.enable_dynamic_cache:
                # ä½¿ç”¨åŠ¨æ€ç¼“å­˜ç³»ç»Ÿ
                cache_key = self.dynamic_cache.generate_cache_key_v2(market_data)
                atr_percentage = market_data.get('atr_percentage', 0)
                dynamic_duration = self.dynamic_cache.get_dynamic_cache_duration(atr_percentage)

                logger.info(f"ğŸ”„ ä½¿ç”¨åŠ¨æ€ç¼“å­˜ç³»ç»Ÿ - ATR: {atr_percentage:.2f}%, ç¼“å­˜æ—¶é—´: {dynamic_duration}ç§’")
            else:
                # ä½¿ç”¨ä¼ ç»Ÿç¼“å­˜ç³»ç»Ÿ
                cache_key = self._generate_cache_key(market_data)
                dynamic_duration = self.config.cache_duration

            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
            if cache_key in self.cache:
                cached_result = self.cache[cache_key]
                cache_duration = dynamic_duration if self.config.enable_dynamic_cache else self.config.cache_duration

                if (datetime.now() - cached_result['timestamp']).seconds < cache_duration:
                    logger.info("ä½¿ç”¨ç¼“å­˜çš„AIä¿¡å·")
                    self.dynamic_cache.record_cache_hit()  # è®°å½•ç¼“å­˜å‘½ä¸­
                    cache_monitor.record_hit(cache_key, 0.0)  # è®°å½•åˆ°æ€§èƒ½ç›‘æ§å™¨

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç¼“å­˜å¤±æ•ˆï¼ˆæ™ºèƒ½å¤±æ•ˆæœºåˆ¶ï¼‰
                    if self.config.enable_dynamic_cache:
                        should_invalidate, reason = self.dynamic_cache.should_invalidate_cache(market_data, cached_result.get('market_snapshot', {}))
                        if should_invalidate:
                            logger.info(f"ğŸ”„ æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ: {reason}")
                            del self.cache[cache_key]  # åˆ é™¤å¤±æ•ˆç¼“å­˜
                            self.dynamic_cache.record_cache_eviction()
                            cache_monitor.record_eviction(cache_key, reason)  # è®°å½•å¤±æ•ˆåˆ°æ€§èƒ½ç›‘æ§å™¨
                        else:
                            # å¦‚æœæœ‰ç¼“å­˜çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
                            if 'success_count' in cached_result:
                                success_count = cached_result['success_count']
                                fail_count = cached_result['fail_count']
                                success_providers = cached_result['success_providers']
                                total = success_count + fail_count
                                logger.info(f"ğŸ“Š å¤šAIä¿¡å·è·å–ç»Ÿè®¡: æˆåŠŸ={success_count}, å¤±è´¥={fail_count}, æ€»è®¡={total}")
                                logger.info(f"âœ… æˆåŠŸæä¾›å•†: {success_providers if success_providers else 'æ— '}")
                            # è¿”å›ä¿¡å·å¹¶æ ‡è®°ä¸ºç¼“å­˜ç»“æœ
                            signals = cached_result['signals']
                            for signal in signals:
                                signal['_from_cache'] = True  # æ·»åŠ æ ‡è®°è¡¨ç¤ºè¿™æ˜¯ç¼“å­˜çš„ä¿¡å·
                            return signals
                    else:
                        # ä¼ ç»Ÿç¼“å­˜é€»è¾‘
                        if 'success_count' in cached_result:
                            success_count = cached_result['success_count']
                            fail_count = cached_result['fail_count']
                            success_providers = cached_result['success_providers']
                            total = success_count + fail_count
                            logger.info(f"ğŸ“Š å¤šAIä¿¡å·è·å–ç»Ÿè®¡: æˆåŠŸ={success_count}, å¤±è´¥={fail_count}, æ€»è®¡={total}")
                            logger.info(f"âœ… æˆåŠŸæä¾›å•†: {success_providers if success_providers else 'æ— '}")
                        # è¿”å›ä¿¡å·å¹¶æ ‡è®°ä¸ºç¼“å­˜ç»“æœ
                        signals = cached_result['signals']
                        for signal in signals:
                            signal['_from_cache'] = True  # æ·»åŠ æ ‡è®°è¡¨ç¤ºè¿™æ˜¯ç¼“å­˜çš„ä¿¡å·
                        return signals

            self.dynamic_cache.record_cache_miss()  # è®°å½•ç¼“å­˜æœªå‘½ä¸­
            cache_monitor.record_miss(cache_key)  # è®°å½•åˆ°æ€§èƒ½ç›‘æ§å™¨

            # è®°å½•å½“å‰AIå†³ç­–æ¨¡å¼
            from ..config import load_config
            config = load_config()
            ai_mode = "èåˆæ¨¡å¼" if config.ai.use_multi_ai_fusion else "å•ä¸€æ¨¡å¼"
            logger.info(f"ğŸ¤– AIå†³ç­–æ¨¡å¼: {ai_mode} (æä¾›å•†: {self.providers})")

            # åŠ¨æ€æ¨¡å‹é€‰æ‹©
            if self.config.enable_dynamic_model_selection:
                logger.info("ğŸ” æ­£åœ¨åŸºäºå¸‚åœºæ¡ä»¶é€‰æ‹©æœ€ä¼˜æ¨¡å‹...")
                optimal_models = model_selector.select_models(market_data)

                # è®°å½•é€‰æ‹©çš„æ¨¡å‹ï¼ˆä½†ä¸æ›´æ–°é…ç½®ï¼Œå› ä¸ºæ¨¡å‹åç§°æ˜¯ç¡¬ç¼–ç åœ¨å®¢æˆ·ç«¯çš„ï¼‰
                for provider, model in optimal_models.items():
                    if provider != 'reason' and provider in self.providers:
                        logger.info(f"  {provider.upper()} ä½¿ç”¨æ¨¡å‹: {model}")

                # æ˜¾ç¤ºæˆæœ¬ä¼°ç®—
                estimated_cost = model_selector.get_cost_estimate(optimal_models)
                logger.info(f"  é¢„ä¼°APIæˆæœ¬: ${estimated_cost:.4f}/æ¬¡")

            signals = []
            results = []
            success_count = 0
            fail_count = 0
            success_providers = []

            if self.config.use_multi_ai and len(self.providers) > 1:
                # å¤šAIæ¨¡å¼
                logger.info(f"ğŸš€ å¹¶è¡Œè·å–å¤šAIä¿¡å·: {self.providers}")
                signals = await self._generate_multi_ai_signals(market_data)
            else:
                # å•AIæ¨¡å¼
                provider = self.providers[0] if self.providers else "fallback"
                logger.info(f"ğŸ¯ ä½¿ç”¨å•ä¸€AIä¿¡å·: {provider}")
                signal = await self._generate_single_ai_signal(market_data)
                if signal:
                    signals = [signal]
                    results = [signal]
                    success_count = 1
                    success_providers = [provider]

            # ç¼“å­˜ç»“æœ - å­˜å‚¨ä¸ªä½“ä¿¡å·å’Œæœ€ç»ˆä¿¡å·
            cache_data = {
                'individual_signals': results,  # ä¿å­˜ä¸ªä½“æä¾›å•†ä¿¡å·
                'signals': signals,  # ä¿å­˜æœ€ç»ˆä¿¡å·ï¼ˆå¯èƒ½åŒ…å«èåˆä¿¡å·ï¼‰
                'success_count': success_count,
                'fail_count': fail_count,
                'success_providers': success_providers,
                'timestamp': datetime.now()
            }

            # å¦‚æœä½¿ç”¨åŠ¨æ€ç¼“å­˜ï¼Œä¿å­˜å¸‚åœºå¿«ç…§ç”¨äºæ™ºèƒ½å¤±æ•ˆæ£€æµ‹
            if self.config.enable_dynamic_cache and hasattr(self, 'market_snapshot'):
                cache_data['market_snapshot'] = self.market_snapshot

            self.cache[cache_key] = cache_data

            return signals

        except Exception as e:
            logger.error(f"ç”ŸæˆAIä¿¡å·å¤±è´¥: {e}")
            # ä½¿ç”¨å›é€€ä¿¡å·
            return await self._generate_fallback_signals(market_data)

    async def _generate_single_ai_signal(self, market_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆå•ä¸ªAIä¿¡å·"""
        try:
            from ..config import load_config
            config = load_config()

            # é€‰æ‹©æä¾›å•† - ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤æä¾›å•†
            provider = config.ai.ai_default_provider
            if provider not in self.providers and self.providers:
                provider = self.providers[0]

            # ç”Ÿæˆä¿¡å·
            if provider == "fallback":
                logger.info(f"ğŸ”„ ä½¿ç”¨å›é€€ä¿¡å·ç­–ç•¥")
                signal = await self._generate_fallback_signal(market_data)
            else:
                logger.info(f"ğŸ“¡ è¯·æ±‚ {provider.upper()} ä¿¡å·...")
                signal = await self.ai_client.generate_signal(provider, market_data)

            # è®°å½•ä¿¡å·è¯¦æƒ…
            if signal:
                # AIæä¾›å•†ä½¿ç”¨ 'signal' å­—æ®µï¼Œä¸æ˜¯ 'action'
                action = signal.get('signal', signal.get('action', 'UNKNOWN'))
                confidence = signal.get('confidence', 0)
                reason = signal.get('reason', '')

                # æ·»åŠ ä¿¡å·ç†ç”±åˆ°æ—¥å¿—
                if reason:
                    logger.info(f"âœ… {provider.upper()} æˆåŠŸ: {action} (ä¿¡å¿ƒ: {confidence:.2f}) - {reason}")
                else:
                    logger.info(f"âœ… {provider.upper()} æˆåŠŸ: {action} (ä¿¡å¿ƒ: {confidence:.2f})")

                # è®°å½•APIè°ƒç”¨æˆæœ¬åˆ°ç›‘æ§å™¨
                estimated_cost = 0.001  # ä¼°ç®—æ¯æ¬¡APIè°ƒç”¨æˆæœ¬
                cache_monitor.record_api_call(provider, estimated_cost)
            else:
                logger.error(f"âŒ {provider.upper()} è¿”å›ç©ºä¿¡å·")

            return signal

        except Exception as e:
            logger.error(f"ç”Ÿæˆå•AIä¿¡å·å¤±è´¥: {e}")
            if self.config.fallback_enabled:
                return await self._generate_fallback_signal(market_data)
            return None

    async def _generate_multi_ai_signals(self, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå¤šAIä¿¡å·"""
        try:
            # å¹¶è¡Œè·å–æ‰€æœ‰æä¾›å•†çš„ä¿¡å·
            tasks = []
            for provider in self.providers:
                if provider == "fallback":
                    task = asyncio.create_task(self._generate_fallback_signal(market_data))
                else:
                    task = asyncio.create_task(self.ai_client.generate_signal(provider, market_data))
                tasks.append((provider, task))

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶è®°å½•ç»“æœ
            results = []
            success_count = 0
            fail_count = 0
            success_providers = []

            for provider, task in tasks:
                try:
                    signal = await task
                    if signal:
                        # æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼
                        confidence = signal.get('confidence', 0)
                        if confidence >= self.config.min_confidence:
                            signal['provider'] = provider
                            results.append(signal)
                            success_count += 1
                            success_providers.append(provider)

                            # è®°å½•è¯¦ç»†çš„ä¿¡å·ä¿¡æ¯
                            action = signal.get('signal', signal.get('action', 'UNKNOWN'))
                            reason = signal.get('reason', '')
                            if reason:
                                logger.info(f"âœ… {provider.upper()} æˆåŠŸ: {action} (ä¿¡å¿ƒ: {confidence:.2f}) - {reason}")
                            else:
                                logger.info(f"âœ… {provider.upper()} æˆåŠŸ: {action} (ä¿¡å¿ƒ: {confidence:.2f})")

                            # è®°å½•APIè°ƒç”¨æˆæœ¬åˆ°ç›‘æ§å™¨
                            estimated_cost = 0.001  # ä¼°ç®—æ¯æ¬¡APIè°ƒç”¨æˆæœ¬
                            cache_monitor.record_api_call(provider, estimated_cost)
                        else:
                            logger.warning(f"âš ï¸  {provider.upper()} ç½®ä¿¡åº¦ä¸è¶³: {confidence:.2f} < {self.config.min_confidence}")
                            fail_count += 1
                    else:
                        logger.error(f"âŒ {provider.upper()} è¿”å›ç©ºä¿¡å·")
                        fail_count += 1

                except Exception as e:
                    logger.error(f"âŒ {provider.upper()} ä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
                    fail_count += 1

            # è®°å½•ç»Ÿè®¡ä¿¡æ¯ - è¿™æ˜¯å®é™…æä¾›å•†çš„ç»Ÿè®¡
            total = success_count + fail_count
            logger.info(f"ğŸ“Š å¤šAIä¿¡å·è·å–ç»Ÿè®¡: æˆåŠŸ={success_count}, å¤±è´¥={fail_count}, æ€»è®¡={total}")
            logger.info(f"âœ… æˆåŠŸæä¾›å•†: {success_providers if success_providers else 'æ— '}")

            # ä¿å­˜å¸‚åœºå¿«ç…§åˆ°å®ä¾‹å˜é‡ï¼ˆç”¨äºæ™ºèƒ½å¤±æ•ˆæ£€æµ‹ï¼‰
            self.market_snapshot = {
                'price': market_data.get('price', 0),
                'volume': market_data.get('volume', 0),
                'atr': market_data.get('atr', 0),
                'atr_percentage': market_data.get('atr_percentage', 0),
                'technical_data': market_data.get('technical_data', {})
            }

            # å¦‚æœå¯ç”¨äº†èåˆï¼Œè¿›è¡Œä¿¡å·èåˆ
            # åªè¦æœ‰è‡³å°‘1ä¸ªæˆåŠŸçš„ä¿¡å·ï¼Œå°±è¿›è¡Œèåˆï¼ˆéƒ¨åˆ†å¤±è´¥ä¸å½±å“èåˆå†³ç­–ï¼‰
            if self.config.fusion_enabled and len(results) >= 1:
                # è®°å½•éƒ¨åˆ†å¤±è´¥çš„æƒ…å†µ
                if fail_count > 0:
                    logger.info(f"âš ï¸  éƒ¨åˆ†æä¾›å•†å¤±è´¥: {fail_count}/{total}ï¼Œä½¿ç”¨{len(results)}ä¸ªæˆåŠŸä¿¡å·è¿›è¡Œèåˆ")
                from ..config import load_config
                config = load_config()

                # è·å–èåˆé…ç½®
                fusion_strategy = config.ai.ai_fusion_strategy
                fusion_threshold = config.ai.ai_fusion_threshold
                fusion_weights = config.ai.ai_fusion_weights

                logger.info(f"ğŸ”§ å¼€å§‹ä¿¡å·èåˆ - ç­–ç•¥: {fusion_strategy}, é˜ˆå€¼: {fusion_threshold}")
                if fusion_weights:
                    logger.info(f"âš–ï¸  èåˆæƒé‡: {fusion_weights}")

                fused_signal = await self.ai_fusion.fuse_signals(
                    results,
                    strategy=fusion_strategy,
                    threshold=fusion_threshold,
                    weights=fusion_weights
                )
                if fused_signal:
                    action = fused_signal.get('signal', fused_signal.get('action', 'UNKNOWN'))
                    confidence = fused_signal.get('confidence', 0)
                    logger.info(f"ğŸ”® èåˆç»“æœ: {action} (ç½®ä¿¡åº¦: {confidence:.2f})")
                    return [fused_signal]
                else:
                    logger.warning("âš ï¸  ä¿¡å·èåˆå¤±è´¥ï¼Œè¿”å›åŸå§‹ä¿¡å·")

            return results

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤šAIä¿¡å·å¤±è´¥: {e}")
            return await self._generate_fallback_signals(market_data)

    async def _generate_fallback_signals(self, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå›é€€ä¿¡å·"""
        try:
            signal = await self._generate_fallback_signal(market_data)
            return [signal] if signal else []

        except Exception as e:
            logger.error(f"ç”Ÿæˆå›é€€ä¿¡å·å¤±è´¥: {e}")
            return []

    async def _generate_fallback_signal(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå›é€€ä¿¡å·ï¼ˆåŸºäºç®€å•è§„åˆ™ï¼‰"""
        try:
            # åŸºäºä»·æ ¼çš„ç®€å•ç­–ç•¥
            current_price = market_data.get('price', 0)
            high = market_data.get('high', current_price)
            low = market_data.get('low', current_price)

            if current_price == 0:
                return {
                    'signal': 'HOLD',
                    'confidence': 0.5,
                    'reason': 'ä»·æ ¼æ•°æ®æ— æ•ˆ',
                    'timestamp': datetime.now().isoformat(),
                    'provider': 'fallback'
                }

            # è®¡ç®—ä»·æ ¼ä½ç½®ï¼ˆ0-1ï¼‰
            if high > low:
                price_position = (current_price - low) / (high - low)
            else:
                price_position = 0.5

            # ç”Ÿæˆä¿¡å·
            if price_position > 0.8:
                signal = 'SELL'
                confidence = 0.6
                reason = 'ä»·æ ¼æ¥è¿‘å½“æ—¥é«˜ç‚¹'
            elif price_position < 0.2:
                signal = 'BUY'
                confidence = 0.6
                reason = 'ä»·æ ¼æ¥è¿‘å½“æ—¥ä½ç‚¹'
            else:
                signal = 'HOLD'
                confidence = 0.5
                reason = 'ä»·æ ¼å¤„äºä¸­é—´åŒºåŸŸ'

            return {
                'signal': signal,
                'confidence': confidence,
                'reason': reason,
                'timestamp': datetime.now().isoformat(),
                'provider': 'fallback'
            }

        except Exception as e:
            logger.error(f"å›é€€ä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
            return {
                'signal': 'HOLD',
                'confidence': 0.3,
                'reason': f'å›é€€ä¿¡å·ç”Ÿæˆå¤±è´¥: {str(e)}',
                'timestamp': datetime.now().isoformat(),
                'provider': 'fallback'
            }

    def _generate_cache_key(self, market_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜é”® - åŸºäºä»·æ ¼åŒºé—´è€Œéç²¾ç¡®å€¼ï¼Œæé«˜ç¼“å­˜å‘½ä¸­ç‡"""
        # è·å–å…³é”®æ•°æ®
        price = market_data.get('price', 0)
        volume = market_data.get('volume', 0)

        # ä½¿ç”¨åŠ¨æ€ç¼“å­˜ç®¡ç†å™¨çš„åˆ†æ¡¶ç­–ç•¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config.enable_dynamic_cache and hasattr(self, 'dynamic_cache'):
            # ä½¿ç”¨æ›´ç»†ç²’åº¦çš„ä»·æ ¼åˆ†æ¡¶
            price_bucket = self.dynamic_cache.calculate_price_bucket(price, bucket_size=50.0)
        else:
            # å°†ä»·æ ¼å››èˆäº”å…¥åˆ°æœ€è¿‘çš„100ç¾å…ƒï¼Œå‡å°‘ç¼“å­˜é”®æ•°é‡
            price_bucket = round(float(price) / 100) * 100 if price > 0 else 0

        # å°†æˆäº¤é‡å››èˆäº”å…¥åˆ°æœ€è¿‘çš„åˆç†å•ä½
        if volume > 1000000:
            volume_bucket = round(volume / 100000) * 100000
        elif volume > 100000:
            volume_bucket = round(volume / 10000) * 10000
        else:
            volume_bucket = round(volume / 1000) * 1000

        # å½“å‰æ—¶é—´çš„å°æ—¶ï¼ˆä¸æ˜¯ç²¾ç¡®æ—¶é—´ï¼‰ï¼Œå…è®¸1å°æ—¶å†…çš„ç¼“å­˜å¤ç”¨
        current_hour = datetime.now().hour

        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"ai_signal_{price_bucket}_{volume_bucket}_{current_hour}"

        logger.debug(f"ç”Ÿæˆç¼“å­˜é”®: {cache_key} (ä»·æ ¼æ¡¶: {price_bucket}, æˆäº¤é‡æ¡¶: {volume_bucket}, å°æ—¶: {current_hour})")
        return cache_key

    def get_provider_status(self) -> Dict[str, Any]:
        """è·å–æä¾›å•†çŠ¶æ€"""
        # è·å–ç¼“å­˜ç›‘æ§ç»Ÿè®¡
        cache_stats = cache_monitor.get_cache_stats()
        dynamic_cache_stats = self.dynamic_cache.get_cache_stats() if hasattr(self, 'dynamic_cache') else {}

        return {
            'available_providers': self.providers,
            'primary_provider': self.config.primary_provider,
            'multi_ai_enabled': self.config.use_multi_ai,
            'fallback_enabled': self.config.fallback_enabled,
            'cache_size': len(self.cache),
            'dynamic_cache_enabled': self.config.enable_dynamic_cache,
            'cache_hit_rate': cache_stats.get('hit_rate', 0),
            'dynamic_cache_stats': dynamic_cache_stats
        }

    def clear_cache(self) -> None:
        """æ¸…é™¤ç¼“å­˜"""
        self.cache.clear()
        logger.info("AIä¿¡å·ç¼“å­˜å·²æ¸…é™¤")

    def get_cache_report(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜æ€§èƒ½æŠ¥å‘Š"""
        return cache_monitor.generate_report()

    def save_cache_report(self, filename: Optional[str] = None) -> str:
        """ä¿å­˜ç¼“å­˜æ€§èƒ½æŠ¥å‘Š"""
        return cache_monitor.save_report(filename)

    def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€"""
        base_status = super().get_status()

        # è·å–å½“å‰æ¨¡å‹é…ç½®
        current_models = {}
        # é¢„å®šä¹‰çš„æ¨¡å‹æ˜ å°„
        provider_models = {
            'kimi': 'moonshot-v1-32k',
            'deepseek': 'deepseek-chat',
            'qwen': 'qwen-turbo',
            'openai': 'gpt-3.5-turbo'
        }

        for provider in self.providers:
            if provider in provider_models:
                current_models[provider] = provider_models[provider]
            else:
                current_models[provider] = 'unknown'

        base_status.update({
            'providers': self.providers,
            'use_multi_ai': self.config.use_multi_ai,
            'cache_size': len(self.cache),
            'provider_status': self.get_provider_status(),
            'dynamic_model_selection': self.config.enable_dynamic_model_selection,
            'current_models': current_models,
            'model_selection_stats': model_selector.get_selection_stats()
        })
        return base_status

# å…¨å±€AIç®¡ç†å™¨å®ä¾‹
_ai_manager_instance: Optional[AIManager] = None

# åˆ›å»ºAIç®¡ç†å™¨çš„å·¥å‚å‡½æ•°
async def create_ai_manager() -> AIManager:
    """åˆ›å»ºAIç®¡ç†å™¨å®ä¾‹"""
    global _ai_manager_instance

    from ..config import load_config
    config = load_config()

    ai_config = AIManagerConfig(
        name="AlphaAIManager",
        use_multi_ai=config.ai.use_multi_ai_fusion,  # ä½¿ç”¨æ–°çš„ fusion æ¨¡å¼åˆ¤æ–­
        primary_provider=config.ai.ai_default_provider,  # ä½¿ç”¨æ–°çš„é»˜è®¤æä¾›å•†å‚æ•°
        fallback_enabled=config.ai.fallback_enabled,
        cache_duration=config.ai.cache_duration,
        min_confidence=config.ai.min_confidence_threshold,
        fusion_enabled=config.ai.use_multi_ai_fusion  # èåˆæ¨¡å¼ä¸å¤šAIæ¨¡å¼ä¿æŒä¸€è‡´
    )

    _ai_manager_instance = AIManager(ai_config)
    await _ai_manager_instance.initialize()
    return _ai_manager_instance

async def get_ai_manager() -> AIManager:
    """è·å–å…¨å±€AIç®¡ç†å™¨å®ä¾‹"""
    global _ai_manager_instance

    if _ai_manager_instance is None:
        raise RuntimeError("AIç®¡ç†å™¨å°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ create_ai_manager()")

    return _ai_manager_instance

async def cleanup_ai_manager() -> None:
    """æ¸…ç†å…¨å±€AIç®¡ç†å™¨å®ä¾‹"""
    global _ai_manager_instance

    if _ai_manager_instance is not None:
        await _ai_manager_instance.cleanup()
        _ai_manager_instance = None